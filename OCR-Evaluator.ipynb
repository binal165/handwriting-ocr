{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating OCR Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Segmantation model:\n",
      "INFO:tensorflow:Restoring parameters from models/gap-clas/CNN-CG\n",
      "INFO:tensorflow:Restoring parameters from models/gap-clas/large/CNN-CG\n",
      "INFO:tensorflow:Restoring parameters from models/gap-clas/RNN/Bi-RNN\n",
      "INFO:tensorflow:Restoring parameters from models/gap-clas/RNN/Bi-RNN-dense\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "from collections import Counter\n",
    "import unidecode\n",
    "\n",
    "# Import Widgets\n",
    "from ipywidgets import Button, Text, HBox, VBox\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Import costume functions, corresponding to notebooks\n",
    "#from ocr import page, words, charSeg\n",
    "from ocr.normalization import letterNorm\n",
    "from ocr import charSeg\n",
    "# Helpers\n",
    "from ocr.helpers import implt, resize\n",
    "from ocr.datahelpers import loadWordsData, char2idx, idx2char\n",
    "from ocr.tfhelpers import Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "LANG = 'en'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/char-clas/en/CharClassifier\n",
      "INFO:tensorflow:Restoring parameters from models/char-clas/en/Bi-RNN/model_2\n",
      "INFO:tensorflow:Restoring parameters from models/char-clas/en/Bi-RNN/model_1\n",
      "INFO:tensorflow:Restoring parameters from models/word-clas/en/WordClassifier\n"
     ]
    }
   ],
   "source": [
    "charClass_1 = Graph('models/char-clas/' + LANG + '/CharClassifier')\n",
    "charClass_2 = Graph('models/char-clas/' + LANG + '/Bi-RNN/model_2', 'prediction')\n",
    "charClass_3 = Graph('models/char-clas/' + LANG + '/Bi-RNN/model_1', 'prediction')\n",
    "\n",
    "wordClass = Graph('models/word-clas/' + LANG + '/WordClassifier', 'prediction_infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading words...\n",
      "-> Number of words: 250\n",
      "Number of chars: 1228\n"
     ]
    }
   ],
   "source": [
    "images, labels = loadWordsData('data/test_words/' + LANG, loadGaplines=False)\n",
    "\n",
    "if LANG == 'en':\n",
    "    for i in range(len(labels)):\n",
    "        labels[i] = unidecode.unidecode(labels[i])\n",
    "        \n",
    "print('Number of chars:', sum(len(l) for l in labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Words\n",
    "WORDS = {}\n",
    "with open('data/' + LANG + '_50k.txt') as f:\n",
    "    for line in f:\n",
    "        if LANG == 'en':\n",
    "            WORDS[unidecode.unidecode(line.split(\" \")[0])] = int(line.split(\" \")[1])\n",
    "        else:\n",
    "            WORDS[line.split(\" \")[0]] = int(line.split(\" \")[1])\n",
    "WORDS = Counter(WORDS)\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    if word in WORDS:\n",
    "        return word\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    \n",
    "    if LANG == 'cz':\n",
    "        letters = 'aábcčdďeéěfghiíjklmnňoópqrřsštťuúůvwxyýzž'\n",
    "    else:\n",
    "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordCycler:\n",
    "    \"\"\" Cycle through the words and recognise them \"\"\" \n",
    "    def __init__(self, images, labels, charClass):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.charClass = charClass\n",
    "        \n",
    "        self.totalChars = sum([len(l) for l in labels])\n",
    "        \n",
    "        self.evaluateAll()\n",
    "        \n",
    "    def recogniseWord(self, img):\n",
    "        slider = (60, 15)\n",
    "        length = img.shape[1]//slider[1]\n",
    "        \n",
    "        input_seq = np.zeros((1, length, slider[0] * slider[1]), dtype=np.float32)\n",
    "        input_seq[0][:] = [img[:, loc * slider[1]: (loc+1) * slider[1]].flatten()\n",
    "                           for loc in range(length)]                                \n",
    "        input_seq = input_seq.swapaxes(0, 1)\n",
    "        \n",
    "        targets = np.zeros((1, 1), dtype=np.int32)                        \n",
    "        pred = self.charClass.eval_feed({'encoder_inputs:0': input_seq,\n",
    "                                         'encoder_inputs_length:0': [length],\n",
    "                                         'decoder_targets:0': targets,\n",
    "                                         'keep_prob:0': 1})[0]\n",
    "                  \n",
    "        word = ''\n",
    "        for i in pred:\n",
    "            if word == 1:\n",
    "                break\n",
    "            else:\n",
    "                word += idx2char(i)\n",
    "\n",
    "        return word.lower()\n",
    "    \n",
    "    \n",
    "    def countCorrect(self, pred, label):\n",
    "        correct = 0\n",
    "        for i in range(min(len(pred), len(label))):\n",
    "            if pred[i] == label.lower()[i]:\n",
    "                correct += 1\n",
    "                \n",
    "        return correct            \n",
    "        \n",
    "\n",
    "    def evaluateAll(self):\n",
    "        self.evaluate()\n",
    "        \n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\" Evaluate accuracy of the word classification \"\"\"\n",
    "        print()\n",
    "        print(\"STATS: Seq2Seq\")\n",
    "        print(self.labels[0], ':', self.recogniseWord(self.images[0]))\n",
    "        start_time = time.time()\n",
    "        correct = 0\n",
    "        correctWithCorrection = 0\n",
    "        for i in range(len(self.images)):\n",
    "            word = self.recogniseWord(self.images[i])\n",
    "            correct += self.countCorrect(word,\n",
    "                                         self.labels[i])\n",
    "            correctWithCorrection += self.countCorrect(correction(word),\n",
    "                                                       self.labels[i])\n",
    "        print(\"Correct/Total: %s / %s\" % (correct, self.totalChars))\n",
    "        print(\"Accuracy: %s %%\" % round(correct/self.totalChars * 100, 4))\n",
    "        print(\"Accuracy with correction: %s %%\" % round(correctWithCorrection/self.totalChars * 100, 4))\n",
    "        print(\"--- %s seconds ---\" % round(time.time() - start_time, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cycler:\n",
    "    \"\"\" Cycle through the words and recognise them \"\"\" \n",
    "    def __init__(self, images, labels, charClass, charRNN=False):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.charClass = charClass\n",
    "        self.charRNN = charRNN\n",
    "        \n",
    "        self.totalChars = sum([len(l) for l in labels])\n",
    "        \n",
    "        self.evaluateAll()\n",
    "        \n",
    "    def recogniseWord(self, img, gapRNN=False, norm1=False, norm2=False, large=False):\n",
    "        if large:\n",
    "            border = 60\n",
    "        else:\n",
    "            border = 15\n",
    "        img = cv2.copyMakeBorder(img,\n",
    "                                 0, 0, border, border,\n",
    "                                 cv2.BORDER_CONSTANT,\n",
    "                                 value=[0, 0, 0])\n",
    "        if norm1:\n",
    "            gapImg = (img - np.mean(img)) / max(np.std(img), 1.0 / math.sqrt(img.size))\n",
    "        else:\n",
    "            gapImg = img\n",
    "        gaps = charSeg.segmentation(gapImg, RNN=gapRNN, large=large)\n",
    "        \n",
    "        chars = []\n",
    "        for i in range(len(gaps)-1):\n",
    "            char = img[:, gaps[i]:gaps[i+1]]\n",
    "            # TODO None type error after treshold\n",
    "            char, dim = letterNorm(char, dim=True)\n",
    "            # TODO Test different values\n",
    "            if dim[0] > 4 and dim[1] > 4:\n",
    "                if norm2:\n",
    "                    char = (char - np.mean(char)) / max(np.std(char), 1.0 / math.sqrt(char.size))\n",
    "                else:\n",
    "                    char = char\n",
    "                chars.append(char.flatten())\n",
    "                \n",
    "        chars = np.array(chars)\n",
    "        \n",
    "        if self.charRNN:\n",
    "            pred = self.charClass.eval_feed({'inputs:0': [chars],\n",
    "                                             'length:0': [len(chars)],\n",
    "                                             'keep_prob:0': 1})[0]\n",
    "        else:\n",
    "            pred = self.charClass.run(chars)\n",
    "        \n",
    "        word = ''\n",
    "        for c in pred:\n",
    "            # word += CHARS[charIdx]\n",
    "            word += idx2char(c)\n",
    "        \n",
    "        return word.lower()\n",
    "    \n",
    "    \n",
    "    def countCorrect(self, pred, label):\n",
    "        correct = 0\n",
    "        for i in range(min(len(pred), len(label))):\n",
    "            if pred[i] == label.lower()[i]:\n",
    "                correct += 1\n",
    "                \n",
    "        return correct            \n",
    "        \n",
    "\n",
    "    def evaluateAll(self):\n",
    "        self.evaluate(True, True, False, False)\n",
    "        self.evaluate(True, False, False, True)\n",
    "#         self.evaluate(True, True, True)\n",
    "        self.evaluate(False, False, False, False)\n",
    "        self.evaluate(False, False, False, True)\n",
    "        \n",
    "\n",
    "    def evaluate(self, gapRNN, norm1, norm2, large=False):\n",
    "        \"\"\" Evaluate accuracy of the word classification \"\"\"\n",
    "        print()\n",
    "        print(\"STATS: gapRNN - %s, charRNN - %s, gapNorm - %s, charNorm - %s, large - %s\" %\n",
    "              (gapRNN, self.charRNN, norm1, norm2, large))\n",
    "        print(self.labels[0], ':', self.recogniseWord(self.images[0], gapRNN, norm1, norm2, large))\n",
    "        start_time = time.time()\n",
    "        correct = 0\n",
    "        correctWithCorrection = 0\n",
    "        for i in range(len(self.images)):\n",
    "            word = self.recogniseWord(self.images[i], gapRNN, norm1, norm2, large)\n",
    "            correct += self.countCorrect(word,\n",
    "                                         self.labels[i])\n",
    "            correctWithCorrection += self.countCorrect(correction(word),\n",
    "                                                       self.labels[i])\n",
    "        print(\"Correct/Total: %s / %s\" % (correct, self.totalChars))\n",
    "        print(\"Accuracy: %s %%\" % round(correct/self.totalChars * 100, 4))\n",
    "        print(\"Accuracy with correction: %s %%\" %\n",
    "              round(correctWithCorrection/self.totalChars * 100, 4))\n",
    "        print(\"--- %s seconds ---\" % round(time.time() - start_time, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STATS: gapRNN - True, charRNN - False, gapNorm - True, charNorm - False, large - False\n",
      "urges : srpes\n",
      "Correct/Total: 736 / 1228\n",
      "Accuracy: 59.9349 %\n",
      "Accuracy with correction: 64.1694 %\n",
      "--- 52.37 seconds ---\n",
      "\n",
      "STATS: gapRNN - True, charRNN - False, gapNorm - False, charNorm - False, large - True\n",
      "urges : sgee\n",
      "Correct/Total: 156 / 1228\n",
      "Accuracy: 12.7036 %\n",
      "Accuracy with correction: 10.0977 %\n",
      "--- 81.72 seconds ---\n",
      "\n",
      "STATS: gapRNN - False, charRNN - False, gapNorm - False, charNorm - False, large - False\n",
      "urges : trrps\n",
      "Correct/Total: 673 / 1228\n",
      "Accuracy: 54.8046 %\n",
      "Accuracy with correction: 59.5277 %\n",
      "--- 45.93 seconds ---\n",
      "\n",
      "STATS: gapRNN - False, charRNN - False, gapNorm - False, charNorm - False, large - True\n",
      "urges : zrqes\n",
      "Correct/Total: 642 / 1228\n",
      "Accuracy: 52.2801 %\n",
      "Accuracy with correction: 53.5831 %\n",
      "--- 83.13 seconds ---\n",
      "\n",
      "STATS: gapRNN - True, charRNN - True, gapNorm - True, charNorm - False, large - False\n",
      "urges : srqoz\n",
      "Correct/Total: 571 / 1228\n",
      "Accuracy: 46.4984 %\n",
      "Accuracy with correction: 56.1889 %\n",
      "--- 64.07 seconds ---\n",
      "\n",
      "STATS: gapRNN - True, charRNN - True, gapNorm - False, charNorm - False, large - True\n",
      "urges : odesi\n",
      "Correct/Total: 139 / 1228\n",
      "Accuracy: 11.3192 %\n",
      "Accuracy with correction: 8.8762 %\n",
      "--- 90.28 seconds ---\n",
      "\n",
      "STATS: gapRNN - False, charRNN - True, gapNorm - False, charNorm - False, large - False\n",
      "urges : rrrps\n",
      "Correct/Total: 670 / 1228\n",
      "Accuracy: 54.5603 %\n",
      "Accuracy with correction: 57.1661 %\n",
      "--- 50.12 seconds ---\n",
      "\n",
      "STATS: gapRNN - False, charRNN - True, gapNorm - False, charNorm - False, large - True\n",
      "urges : krges\n",
      "Correct/Total: 636 / 1228\n",
      "Accuracy: 51.7915 %\n",
      "Accuracy with correction: 53.013 %\n",
      "--- 87.94 seconds ---\n",
      "\n",
      "STATS: gapRNN - True, charRNN - True, gapNorm - True, charNorm - False, large - False\n",
      "urges : csryss\n",
      "Correct/Total: 283 / 1228\n",
      "Accuracy: 23.0456 %\n",
      "Accuracy with correction: 38.4365 %\n",
      "--- 66.12 seconds ---\n",
      "\n",
      "STATS: gapRNN - True, charRNN - True, gapNorm - False, charNorm - False, large - True\n",
      "urges : ofoen\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a222ab34e05b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m        \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m        \u001b[0mcharClass_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m        charRNN=True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-b0d65a885888>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, images, labels, charClass, charRNN)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotalChars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluateAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecogniseWord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgapRNN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlarge\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-b0d65a885888>\u001b[0m in \u001b[0;36mevaluateAll\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluateAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;31m#         self.evaluate(True, True, True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-b0d65a885888>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, gapRNN, norm1, norm2, large)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mcorrectWithCorrection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecogniseWord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgapRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlarge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             correct += self.countCorrect(word,\n\u001b[1;32m     89\u001b[0m                                          self.labels[i])\n",
      "\u001b[0;32m<ipython-input-13-b0d65a885888>\u001b[0m in \u001b[0;36mrecogniseWord\u001b[0;34m(self, img, gapRNN, norm1, norm2, large)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mgapImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mgaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcharSeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgapImg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgapRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlarge\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlarge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mchars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/handwriting-ocr/ocr/charSeg.py\u001b[0m in \u001b[0;36msegmentation\u001b[0;34m(img, step, RNN, large, debug)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mslider\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlarge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mgaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/handwriting-ocr/ocr/charSeg.py\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(img, step, RNN, large)\u001b[0m\n\u001b[1;32m     31\u001b[0m             pred = segRNNDenseGraph.eval_feed({'inputs:0': input_seq,\n\u001b[1;32m     32\u001b[0m                                                \u001b[0;34m'length:0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                                                'keep_prob:0': 1})[0]\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             pred = segRNNGraph.eval_feed({'inputs:0': input_seq,\n",
      "\u001b[0;32m~/Documents/Github/handwriting-ocr/ocr/tfhelpers.py\u001b[0m in \u001b[0;36meval_feed\u001b[0;34m(self, feed)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;34m\"\"\" Run the specified operation with given feed \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Class cycling through words\n",
    "\n",
    "# WordCycler(images,\n",
    "#            labels,\n",
    "#            wordClass)\n",
    "\n",
    "Cycler(images,\n",
    "       labels,\n",
    "       charClass_1,\n",
    "       charRNN=False)\n",
    "\n",
    "Cycler(images,\n",
    "       labels,\n",
    "       charClass_2,\n",
    "       charRNN=True)\n",
    "\n",
    "Cycler(images,\n",
    "       labels,\n",
    "       charClass_3,\n",
    "       charRNN=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
