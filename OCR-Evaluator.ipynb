{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating OCR Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Segmantation model:\n",
      "INFO:tensorflow:Restoring parameters from models/gap-clas/CNN-CG\n",
      "INFO:tensorflow:Restoring parameters from models/gap-clas/RNN/Bi-RNN-new\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "from collections import Counter\n",
    "import unidecode\n",
    "\n",
    "# Import Widgets\n",
    "from ipywidgets import Button, Text, HBox, VBox\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Import costume functions, corresponding to notebooks\n",
    "from ocr import charSeg\n",
    "from ocr.normalization import letterNorm, imageNorm\n",
    "# from ocr import charSeg\n",
    "# Helpers\n",
    "from ocr.helpers import implt, resize\n",
    "from ocr.datahelpers import loadWordsData, idx2char\n",
    "from ocr.tfhelpers import Graph\n",
    "from ocr.viz import printProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "LANG = 'en'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/char-clas/en/CharClassifier\n",
      "INFO:tensorflow:Restoring parameters from models/word-clas/en/WordClassifier\n",
      "INFO:tensorflow:Restoring parameters from models/word-clas/en/SeqRNN/Classifier\n"
     ]
    }
   ],
   "source": [
    "charClass_1 = Graph('models/char-clas/' + LANG + '/CharClassifier')\n",
    "# charClass_2 = Graph('models/char-clas/' + LANG + '/Bi-RNN/model_2', 'prediction')\n",
    "# charClass_3 = Graph('models/char-clas/' + LANG + '/Bi-RNN/model_1', 'prediction')\n",
    "\n",
    "wordClass = Graph('models/word-clas/' + LANG + '/WordClassifier', 'prediction_infer')\n",
    "wordClass2 = Graph('models/word-clas/' + LANG + '/SeqRNN/Classifier', 'word_prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading words...\n",
      "-> Number of words: 267\n",
      " |████████████████████████████████████████| 100.0% \n",
      "\n",
      "Number of chars: 1356\n"
     ]
    }
   ],
   "source": [
    "images, labels = loadWordsData('data/test_words/' + LANG + '_raw', loadGaplines=False)\n",
    "\n",
    "for i in range(len(images)):\n",
    "    printProgressBar(i, len(images))\n",
    "    images[i] = imageNorm(\n",
    "        cv2.cvtColor(images[i], cv2.COLOR_GRAY2RGB),\n",
    "        60,\n",
    "        border=False,\n",
    "        tilt=True,\n",
    "        hystNorm=True)\n",
    "\n",
    "if LANG == 'en':\n",
    "    for i in range(len(labels)):\n",
    "        labels[i] = unidecode.unidecode(labels[i])\n",
    "print()        \n",
    "print('Number of chars:', sum(len(l) for l in labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Words\n",
    "WORDS = {}\n",
    "with open('data/' + LANG + '_50k.txt') as f:\n",
    "    for line in f:\n",
    "        if LANG == 'en':\n",
    "            WORDS[unidecode.unidecode(line.split(\" \")[0])] = int(line.split(\" \")[1])\n",
    "        else:\n",
    "            WORDS[line.split(\" \")[0]] = int(line.split(\" \")[1])\n",
    "WORDS = Counter(WORDS)\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    if word in WORDS:\n",
    "        return word\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    \n",
    "    if LANG == 'cz':\n",
    "        letters = 'aábcčdďeéěfghiíjklmnňoópqrřsštťuúůvwxyýzž'\n",
    "    else:\n",
    "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCycler:\n",
    "    \"\"\" Cycle through the words and recognise them \"\"\" \n",
    "    def __init__(self, images, labels, charClass, slider=(60, 15)):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.charClass = charClass\n",
    "        self.slider = slider\n",
    "        self.totalChars = sum([len(l) for l in labels])\n",
    "        \n",
    "        self.evaluate()\n",
    "        \n",
    "    def recogniseWord(self, img):\n",
    "        slider = self.slider\n",
    "        length = img.shape[1]//slider[1]\n",
    "        \n",
    "        input_seq = np.zeros((1, length, slider[0] * slider[1]), dtype=np.float32)\n",
    "        input_seq[0][:] = [img[:, loc * slider[1]: (loc+1) * slider[1]].flatten()\n",
    "                           for loc in range(length)]                                \n",
    "        input_seq = input_seq.swapaxes(0, 1)\n",
    "        \n",
    "                              \n",
    "        if slider[1] == 15:\n",
    "            targets = np.zeros((1, 1), dtype=np.int32)  \n",
    "            pred = self.charClass.eval_feed({'encoder_inputs:0': input_seq,\n",
    "                                             'encoder_inputs_length:0': [length],\n",
    "                                             'decoder_targets:0': targets,\n",
    "                                             'keep_prob:0': 1})[0]\n",
    "        else:\n",
    "            targets = np.zeros((1, 1, 4096), dtype=np.int32)  \n",
    "            pred = self.charClass.eval_feed({'encoder_inputs:0': input_seq,\n",
    "                                             'encoder_inputs_length:0': [length],\n",
    "                                             'letter_targets:0': targets,\n",
    "                                             'is_training:0': False,\n",
    "                                             'keep_prob:0': 1})[0]\n",
    "        word = ''\n",
    "        for i in pred:\n",
    "            if word == 1:\n",
    "                break\n",
    "            else:\n",
    "                word += idx2char(i, True)\n",
    "\n",
    "        return word.lower()\n",
    "    \n",
    "    \n",
    "    def countCorrect(self, pred, label):\n",
    "        correct = 0\n",
    "        for i in range(min(len(pred), len(label))):\n",
    "            if pred[i] == label.lower()[i]:\n",
    "                correct += 1\n",
    "                \n",
    "        return correct            \n",
    "\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \"\"\" Evaluate accuracy of the word classification \"\"\"\n",
    "        print()\n",
    "        print(\"STATS: Seq2Seq\")\n",
    "        print(self.labels[1], ':', self.recogniseWord(self.images[1]))\n",
    "        start_time = time.time()\n",
    "        correct = 0\n",
    "        correctWithCorrection = 0\n",
    "        for i in range(len(self.images)):\n",
    "            word = self.recogniseWord(self.images[i])\n",
    "            correct += self.countCorrect(word,\n",
    "                                         self.labels[i])\n",
    "            correctWithCorrection += self.countCorrect(correction(word),\n",
    "                                                       self.labels[i])\n",
    "        print(\"Correct/Total: %s / %s\" % (correct, self.totalChars))\n",
    "        print(\"Accuracy: %s %%\" % round(correct/self.totalChars * 100, 4))\n",
    "        print(\"Accuracy with correction: %s %%\" % round(correctWithCorrection/self.totalChars * 100, 4))\n",
    "        print(\"--- %s seconds ---\" % round(time.time() - start_time, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cycler:\n",
    "    \"\"\" Cycle through the words and recognise them \"\"\" \n",
    "    def __init__(self, images, labels, charClass, charRNN=False):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.charClass = charClass\n",
    "        self.charRNN = charRNN\n",
    "        \n",
    "        self.totalChars = sum([len(l) for l in labels])\n",
    "        \n",
    "        self.evaluateAll()\n",
    "        \n",
    "    def recogniseWord(self, img, gapRNN=False):\n",
    "        img = cv2.copyMakeBorder(img,\n",
    "                                 0, 0, 30, 30,\n",
    "                                 cv2.BORDER_CONSTANT,\n",
    "                                 value=[0, 0, 0])\n",
    "        gaps = charSeg.segmentation(img, RNN=gapRNN)\n",
    "        \n",
    "        chars = []\n",
    "        for i in range(len(gaps)-1):\n",
    "            char = img[:, gaps[i]:gaps[i+1]]\n",
    "            # TODO None type error after treshold\n",
    "            char, dim = letterNorm(char, is_thresh=True, dim=True)\n",
    "            # TODO Test different values\n",
    "            if dim[0] > 4 and dim[1] > 4:\n",
    "                chars.append(char.flatten())\n",
    "                \n",
    "        chars = np.array(chars)\n",
    "        word = ''\n",
    "        if len(chars) != 0:\n",
    "            if self.charRNN:\n",
    "                pred = self.charClass.eval_feed({'inputs:0': [chars],\n",
    "                                                 'length:0': [len(chars)],\n",
    "                                                 'keep_prob:0': 1})[0]\n",
    "            else:\n",
    "                pred = self.charClass.run(chars)\n",
    "                \n",
    "            for c in pred:\n",
    "                # word += CHARS[charIdx]\n",
    "                word += idx2char(c, lang)        \n",
    "        return word.lower()\n",
    "    \n",
    "    \n",
    "    def countCorrect(self, pred, label):\n",
    "        correct = 0\n",
    "        for i in range(min(len(pred), len(label))):\n",
    "            if pred[i] == label.lower()[i]:\n",
    "                correct += 1\n",
    "                \n",
    "        return correct            \n",
    "        \n",
    "\n",
    "    def evaluateAll(self):\n",
    "        self.evaluate(True)\n",
    "#         self.evaluate(False)\n",
    "        \n",
    "\n",
    "    def evaluate(self, gapRNN):\n",
    "        \"\"\" Evaluate accuracy of the word classification \"\"\"\n",
    "        print()\n",
    "        print(\"STATS: gapRNN - %s, charRNN - %s\" % (gapRNN, self.charRNN))\n",
    "        print(self.labels[1], ':', self.recogniseWord(self.images[1], gapRNN))\n",
    "        start_time = time.time()\n",
    "        correct = 0\n",
    "        correctWithCorrection = 0\n",
    "        for i in range(len(self.images)):\n",
    "            word = self.recogniseWord(self.images[i], gapRNN)\n",
    "            correct += self.countCorrect(word,\n",
    "                                         self.labels[i])\n",
    "            correctWithCorrection += self.countCorrect(correction(word),\n",
    "                                                       self.labels[i])\n",
    "        print(\"Correct/Total: %s / %s\" % (correct, self.totalChars))\n",
    "        print(\"Accuracy: %s %%\" % round(correct/self.totalChars * 100, 4))\n",
    "        print(\"Accuracy with correction: %s %%\" %\n",
    "              round(correctWithCorrection/self.totalChars * 100, 4))\n",
    "        print(\"--- %s seconds ---\" % round(time.time() - start_time, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STATS: Seq2Seq\n",
      "spreads : ábqpsjuba\n",
      "Correct/Total: 34 / 1356\n",
      "Accuracy: 2.5074 %\n",
      "Accuracy with correction: 2.8761 %\n",
      "--- 20.75 seconds ---\n",
      "\n",
      "STATS: Seq2Seq\n",
      "spreads : spreadsa\n",
      "Correct/Total: 963 / 1356\n",
      "Accuracy: 71.0177 %\n",
      "Accuracy with correction: 70.059 %\n",
      "--- 35.87 seconds ---\n",
      "\n",
      "STATS: gapRNN - True, charRNN - False\n",
      "spreads : spreads\n",
      "Correct/Total: 1049 / 1356\n",
      "Accuracy: 77.3599 %\n",
      "Accuracy with correction: 80.0147 %\n",
      "--- 61.47 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Cycler at 0x7fe5f26a4ef0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class cycling through words\n",
    "\n",
    "WordCycler(images,\n",
    "           labels,\n",
    "           wordClass)\n",
    "\n",
    "WordCycler(images,\n",
    "           labels,\n",
    "           wordClass2,\n",
    "           (60, 2))\n",
    "\n",
    "Cycler(images,\n",
    "       labels,\n",
    "       charClass_1,\n",
    "       charRNN=False)\n",
    "\n",
    "# Cycler(images,\n",
    "#        labels,\n",
    "#        charClass_2,\n",
    "#        charRNN=True)\n",
    "\n",
    "# Cycler(images,\n",
    "#        labels,\n",
    "#        charClass_3,\n",
    "#        charRNN=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
